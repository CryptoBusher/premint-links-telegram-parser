## Парсер ссылок для premint
Скрипт, который умеет парсить уникальные ссылки из истории сообщений,
выкачанной из телеграм канала, после чего парсить эти ссылки на валид
(преминт еще не закрыт) + парсить все твиттер аккаунты и дискорд сервера, на
которые необходимо подписаться для принятия участия в преминте. Может
так же парсить инфу по вашим преминт ссылкам и игнорировать
список ссылок, который вы определите.

Связь с создателем: https://t.me/CrytoBusher <br>
Залетай сюда, чтоб не пропускать дропы подобных скриптов: https://t.me/CryptoKiddiesClub <br>
И сюда, чтоб общаться с крутыми ребятами: https://t.me/CryptoKiddiesChat <br>

## Особенности
1. Мультипоточность
2. Парсер ссылок из истории телеграм канала
3. Использование собственных преминт ссылок
4. Игнорирование определенного списка преминт ссылок
5. Экспорт информации в удобном для автоматизации или конечного пользователя виде

## Недостатки
1. Иногда парсит не те ссылки (просто ссылку на преминт или еще что - то)
2. Читает только один определенный формат страниц, если софт переходит на страницу проверки результатов и или что - то подобное, но не реальный активный/неактивный преминт - он будет ждать 30 секунд пока поймет, что хединга, который он ищет просто нет (компенсируется многопоточностью)

## Логика работы
1. Юзер выбирает количество потоков
2. Юзер выбирает режим работы (по базе из телеграма или по собственному списку преминтов, который он где - то спиздил)
3. Юзер указывает, игнорировать ли ссылки, которые он указал в определенном текстовом файле
4. Происходит подготовка ссылок согласно критериям
5. Происходит переход по ссылке преминта
6. Скрипт ищет хединг, если он равен надписи "Register" - запоминает преминт как валидный и собирает все твиттер и дискорд ссылки, которые указаны в требованияюх преминта. Если он не находит хединг или хединг равен другому значению - запоминает преминт как невалид.
7. После парсинга всех ссылок - происходит сохранение данных в текстовых файлах

## Первый запуск
1. Устанавливаем Python (желательно последнюю версию)
2. Качаем репозиторий
3. Если у вас хром не 103 версии (вбить в поиске "chrome://version" и посмотреть) - качаем свою версию [тут](https://chromedriver.chromium.org/downloads) и заменяем "chromedriver.exe" в папке проекта
4. Открываем терминал, переходим в папку с файлами и пишем команду "pip install -r requirements.txt"
5. Подготавливаем наши файлы:
   1. Если хотим юзать базу из телеграма - переходим в телеграм канал, нажимаем три точки вверху, жмем "Export chat history", снимаем все галочки, меняем Format "HTML" на "JSON", качаем данные и закидываем файл "result.json" в папку "data"
   2. Если хотим юзать базу из своих ссылок - просто закидываем ссылку в файл "my_links.txt" в папке "data" (вбивайте ссылки с "https://")
   3. Если хотим игнорировать некоторые ссылки, вбиваем их в файл "links_to_ignore.txt" в папке "data"
6. Запускаем скрипт "main.py" (гуглите, если не знаете, как это делается)
7. Вбиваем количество потоков, источник ссылок и режим игнора ссылок из списка
8. На выходе получаем 4 файла:
   1. "final_summary_data.txt" - все данные в одном месте: ссылка_на_преминт,[ссылка_на_твиттер_1,ссылка_на_твиттер_2],[ссылка_на_дискорд_1,ссылка_на_дискорд_2]]
   2. "active_premint_links" - список ссылок на преминт (просто в отдельном файле)
   3. "twitters_to_subscribe" - список ссылок на твиттеры, на которые нужно подписаться (просто в отдельном файле)
   4. "discords_to_enter" - список ссылок на дискорды, в которые нужно вступить (просто в отдельном файле)

